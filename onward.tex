%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan,screen]{acmart}

\usepackage{code}
\usepackage{graphicx}
\usepackage{placeins}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%% The following is specific to Onward! '24-ESSAYS and the paper
%%% '(Programs), Proofs and Refutations (and Tests and Mutants)'
%%% by Alex Groce.
%%%
\setcopyright{acmlicensed}
\acmDOI{10.1145/3689492.3689810}
\acmYear{2024}
\copyrightyear{2024}
\acmISBN{979-8-4007-1215-9/24/10}
\acmConference[Onward! '24]{Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software}{October 23--25, 2024}{Pasadena, CA, USA}
\acmBooktitle{Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! '24), October 23--25, 2024, Pasadena, CA, USA}
\acmSubmissionID{onward24essays-p7-p}
\received{2024-04-25}
\received[accepted]{2024-08-08}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Mutation Driven Development}

\author{Alex Groce}
\orcid{0000-0003-0273-4668}
\affiliation{%
  \institution{Northern Arizona University}
  \city{Flagstaff}
  \country{USA}
}
\email{agroce@gmail.com}

%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Alex Groce}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}

\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10010940.10010992.10010998.10011001</concept_id>
<concept_desc>Software and its engineering~Dynamic analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011074.10011099.10011102.10011103</concept_id>
<concept_desc>Software and its engineering~Software testing and debugging</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Dynamic analysis}
\ccsdesc[500]{Software and its engineering~Software testing and debugging}

\keywords{software testing software verification, proof, counterexample, tests}



\begin{abstract}
Test driven development (TDD) is a controversial and interesting approach to
software development; while many think of ``better tests'' as a
primary \emph{purpose} of TDD, in practice the goal is as much to use
tests to encourage continued progress in coding.   That goal however
rests on the notion that TDD ensures tests are good enough to let you
implement small new features and refactor code without undue fear of
mistakes.  Unfortunately, TDD is not ``self-enforcing'' and standard
TDD practice makes it easy to accidentally skip steps.  By integrating
a phase of focused mutation testing into TDD, however, developers
applying TDD can be sure they are not writing code that is not
supported by the scaffolding of tests.  The incremental nature of TDD
test and production code creation ensures that at no point will
``fixing up'' the mutants be likely to overwhelm the developer, and so
the final result will be tests with excellent code coverage and
mutation score, without a painful effort to ``patch up'' an inadequate
testing effort, and a TDD approach that includes automated checks that
the letter and spirit of TDD are truly being respected, and the
benefits of TDD presumably following in due course.
  \end{abstract}



\maketitle


\section{Introduction}

The first question I should answer: given the abstract, which sounds
like a fairly standard software engineering research paper abstract,
except for the missing part bragging
about a positive experimental evaluation, why is this an Onward! Essay
and not a conventional research paper?

The answer is personal:  I thought of this idea a few years ago, and
have thought about making it a full research project off and on since
then, and I
never managed to actually do so.  A real evaluation of this idea would
require a good graduate student's devotion, and, more importantly,
actual human-subjects experimentation work to arrive at even a
speculative and provisional scientific evaluation of the idea's
efficacy.  I can't think of a useful way to make a purely ``extract
code from public repos and analyze it'' investigation, or (better yet)
a purely mechanical experiment.  Perhaps in a few years it will be
possible to just have LLMs do it all?

I (read: ``my lab'') don't really do human subjects; I don't ever want do
write IRB paperwork.  I do work with people who do human subjects,
from time to time; so I could potentially convince one of those
wonderful folks that this is a good project, and thus avoid doing IRB
paperwork and still make this a ``real'' paper.

But I don't have a huge committment to Test
Driven Development to get me excited enough to try to talk someone
else into spending valuable research productivity time on this idea; I've never used
TDD in writing code myself, and I'm not sure if I think it's a good development
practice.  Nobody I know and trust in the real software industry seems
to do things in a TDD way, which is suggestive.  So it just doesn't
seem worth it to commit to a serious Research Project, likely spanning
over a year, to this idea.

So why not do what we senior researchers usually do in this situation?
Shelve the idea, perhaps mention it to one or two people, and let it
basically die?  I've done this before; there are a good half-dozen
implmentations of test generation ideas I think might be interesting
or effective in my TSTL Python test generation tool, none of which
ever became a paper.  They live only as obscure command line options
to a tool increasingly few people are likely to ever use.  It's sad,
but life is short, and I don't think any of those ideas are likely to
be \emph{really} important, vs. somewhat, occasionally, useful.

\subsubsection{Daniel Jackson Made Me Do It}

I recently read Daniel Jackson's \emph{The Essence of Software}~\cite{essence}, which
is a very enjoyable book.  The supposed topic of the book is an
approach to design that I thought was interesting, but that also seems
more appropriate to UI-heavy software for ``normal people'' than the
kind of code analysis/test generation software I tend to write
myself.  The real value of the book was, for me, twofold:  first, the
long long set of ``notes'' after the main text is a delightful random
walk through software engineering.  Second, Jackson's musings include
a major theme:  we've become too careful in the software engineering
research community.  Given the heroic (for lazy computer scientists,
at least;
obviously almost every research project in SE is a joke compared to
the work of serious systems people, much less biologists or
physicists) effort required for making Real Science that Has Six Good
RQs and Makes it Past the ICSE Program Committee,   There was a time
when SE (or formal methods, where I was living at that time) was far
too accepting of a paper based on application of an approach to a
single toy problem, plus a good writeup.  This was too lacking in
rigor, and there was a very sensible effort to increase the level of
experimental support for claims about software engineering.  I don't
have a strong opinion on how this worked out for more methdological
aspects of SE, but for the most part the increased experimental
validation (and, later, statistical sophistication, or at least competence) was necessary to
make work in more ``technical'' parts of SE, such as software testing,
trustworthy.

However, this was not without a cost:  some of the most important and
influential papers in SE, as Jackson points out, did not rest on a
basis of experimental support, in part because they were more raw
``ideas'' than a narrower scientific claim.

Now, many researchers take ideas that don't satsfy the current rules
for \emph{proper} papers and turn them into blog posts or at least
tweets.  I've done this.  But there's an argument that this limits the
audience to people who already know who you are and watch what you
say.  If your ideas are relevant to another community, one you aren't
part of, this is likely to mean they never reach that audience.

In the past I've written Onward! Essays when the topic was clearly not
one suitable to a standard research paper.  This time, I'm writing an
essay because that seems more responsible than writing a blog post,
and a research paper minus the experimental evidence is just an
essay.  The reader is free to try the idea out, with no guarantee that
it will work, but really --- we know that's the case with most
research, as well, except in the most unusual of circumstances.  So,
onward to the idea.

\section{What is Test Driven Development?}

Test Driven Development (henceforth TDD) has been defined many times~\cite{beck2002test,astels2003test,TDDIBM,TDDAcademy},
in many ways.  Even if you're familliar with TDD, I would like to
revisit the foundations for a moment, because the proposal made here
is formulated with respect to a particular conception of TDD.  Most
definitions of TDD (including this one) properly present it as a
\emph{series of steps to be followed in development}.

\begin{enumerate}
  \item Think of a behavior your software does not yet have,
    but that you want it to have.
    \item Add a test that would pass if that behavior was present, but
      will not pass if it is not.
    \item Run all your tests and see that the newly added test fails.
    \item Make a \emph{small} change that makes the test pass.
    \item Run all the tests; make sure they all succeed now.
      \item Refactor to remove duplication/generally clean the code
        from step 4 up so it doesn't make you ashamed of yourself.
        \item Repeat (go to 1).  Do not, generally, make changes other than by
          this process!
      \end{enumerate}

I added the first step, because you can't really write a test until
you've thought of something to test.

Why write software in this restrictive way?  The benefits proposed
vary, but I think can be summarized as:

\begin{itemize}
  \item By making such small steps, you always have the confidence to
    move forwards.  This may not be the first thing most people think
    of with TDD, but Beck's extremely influential book~\cite{beck2002test} really focuses
    on this.  You never get stuck!  You always have confidence!  You
    are making progress at all times.  Even if you can't actually
    implement the funcitonality at the moment (you haven't figure out
    how), TDD lets you write a \emph{useful test} and a \emph{passing,
      but fake, implementation} and thus have accomplished something.
    Beck thus offers strategies for getting from a fake (e.g., return a
    constant) implementation to a real implementation.
    \item Beck implies and everyone else seems to agree that this
      confidence isn't \emph{just} about the small implementation steps; it's about
      the fact that those steps are accompanied by tests that you know
      will tell you if you mess things up.  You can write code even
      when in doubt because not only are you tackling small pieces you
      should be able to get right, you have tests that you \emph{know}
      will let you know if you don't get it right.
      \item More obviously, should end up with a very good set of unit
        tests if there's nothing in the code you didn't write a test
        for, first.  How could big holes arise in your testing?  You
        should, for example, have very high code coverage (if you
        don't, what's going on?)
        \item Thinking about testing \emph{first} should improve
          testability; you won't implement functionality in a hard to
          test way if you're forced to write the test before the
          implementation.
          \item Similarly, API users will be in your mind: you'll
            always use any APIs you make before you implement them.
            There's a strong expectation in the literature that this
            will produce better overall designs.
            \end{itemize}

My personal experience with TDD consists of:  reading Beck's book and
Grenning's excellent book on TDD for embedded systems~\cite{grenning},
plus a few random papers on the topic (I have forgotten which ones), trying it
out for a few toy Python examples, and, finally, requiring students taking CS 361 at
Oregon State (the first of a two-term software engineering sequence)
to use it to implement Parnas' KWIC (Key Word in Context) example~\cite{parnas1972criteria}.
The students hated it, and thought I was a maniac to insist on their
following strict TDD discipline (and enforcing standard naming conventions
to make the resulting code easy to analyze for coverage and (to get
ahead of ourselves) mutation score).  It's not a way I personally
would write code, in part because of the odd, niche types of code I
write (throwaway scripts for analyzing experimental results, and
testing tools).  On the other hand, the idea of TDD strikes me as
attractive:  I think most software would benefit from better (unit)
tests, of course, I'm a ``testing guy''; writing tests before
implementation to ensure testability strikes me as a really good idea
given all the problems code not designed to be testable can cause (for
one thing, code not designed to be testable also, in my experience,
has limited debuggability, extensibility, and maintainability).


\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}



\end{document}